---
title: "727FinalProject"
author: "Aaron Nesbitt"
date: '2022-11-29'
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

We begin by pulling in necessary packages.
```{r}
library(rtweet)
library(tidyverse)
library(tidytext)
library(ggmap)
library(reader)
```

We search we original tweets, allowing for up to 18 thousand. We ran the function at 5 pm on Tuesday November 29th. 
```{r eval=FALSE, include=FALSE}
musk <- search_tweets(
  q = "musk Twitter, lang:en",
  n = 18000,
  include_rts = FALSE
)
```

Necessary code for Jessica to pull in from her working directory.
```{r}
library(readr)
musktweetsfinal <- read_csv("C:\\Users\\valen\\Downloads\\musktweetsfinal.csv")
View(musktweetsfinal)
```

Necessary code for Aaron to pull in from his working directory.
```{r}
musktweetsfinal <- read_csv("C:\\Users\\aanes\\Documents\\musktweetsfinal.csv")
```

Here I am creating a function before sentiment analysis to eliminate tweets with the word tesla.
```{r}
library(quanteda)

irrelevantWords = c('tesla')

newTweets = data.frame()
irrelevantTweets = data.frame()

for(i in 1:nrow(musktweetsfinal)){
  # break up tweet into individual words
  tweet = musktweetsfinal$text[i]
  tweet = tolower(tweet)
  words = tokens(tweet)
  # if it contains an irrelevant word, put it in the irrelevant data frame
  if(length(intersect(words[['text1']], irrelevantWords))>0){
    irrelevantTweets = rbind(irrelevantTweets, musktweetsfinal[i,])
  }
  else{
    newTweets = rbind(newTweets, musktweetsfinal[i,])
  }
}
```

```{r}
library(SentimentAnalysis)
```



